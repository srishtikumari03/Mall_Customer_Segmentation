# -*- coding: utf-8 -*-
"""Mall_Customer_Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oCZG6bjQTX7W-nGeYItJK0BzKZvrwv3l

# **Introduction**

We are using [Market Customer Segmentation Dataset](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)

Using this dataset we want to understand the customers like who can be easily converge (Target Customers) so that the sense can be given to marketing team and plan the strategy accordingly.

We will do this using K-Mean Algorithm, which is an unsupervised algorithm capable of clustering similar this kind of datapoints very quickly and efficiently.

###**Import Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd  #For data manipulation and analysis
import numpy as np  #For high level mathematical computations and operations
import matplotlib.pyplot as plt #For data visualization
import seaborn as sns  #For drawing attractive and informative statistical graphics.
import plotly.offline as py
py.init_notebook_mode(connected=True)
import plotly.express as px
# %matplotlib inline

# Setting Style and Palette for Seaborn Plots
custom_style = {'axes.labelcolor': 'black',
                'xtick.color': 'black',
                'ytick.color': 'black'}
sns.set_palette('Dark2')
sns.set_style("darkgrid", rc=custom_style)

# Hiding All Warnings
import warnings
warnings.filterwarnings('ignore')

#NOTE!!!!
#Plotly charts are not directly visible in GitHub kindly view the same in Jupyter Lab and ensure that Plotly extension for Jupyter Lab is installed

"""# **Download Data**"""

!pip install kaggle #Install the Kaggle library

! mkdir ~/.kaggle #Make a directory named “.kaggle”

!cp /content/drive/MyDrive/Mall_Customer_Segmentation/kaggle.json ~/.kaggle/kaggle.json #Copy the “kaggle.json” into this new directory

! chmod 600 ~/.kaggle/kaggle.json #Allocate the required permission for this file.

! kaggle datasets download -d vjchoudhary7/customer-segmentation-tutorial-in-python

! unzip customer-segmentation-tutorial-in-python.zip

"""# **Load Dataset**"""

df = pd.read_csv('Mall_Customers.csv')

df.head()

"""# **PreProcess Data**

This case requires to **develop a customer segmentation to define marketing strategy**. The

We are owing a supermarket mall and through membership cards , we have some basic data about out customers. Like:
* Customer ID
* age, gender
* annual income
* spending score

Spending Score is something we assign to the customer based on your defined parameters like customer behavior and purchasing data
"""

df.head()

df.shape

for i in df.columns:
  print(f'column: {i}, dtype: {df[i].dtype}')

"""**Handling Null Values**"""

#checking for null values
df.isna().sum()

"""**Scale Data and Handel Categorical Values**

It is important to scale the input features before running K-Means, or the clusters may be very stretched and K-Means will perform poorly. Scaling the features does not guarantee that all the clusters will be nice and spherical, but it generally improves things.
"""

def encode(data):

  X = data.copy()
  dummies = pd.get_dummies(data['Gender'])
  X[dummies.columns] = dummies

  return X.drop(['Gender'], axis = 1)

X = encode(df)

X.head()

"""**Covariance Matrix**

A covariance matrix is a square matrix giving the covariance between each pair of elements of a given random vector. 
"""

#Plot covariance matrix
X_cov = X.drop(['CustomerID'], axis = 1)
plt.matshow(X_cov.corr())
plt.colorbar()
plt.show()

"""***INFERENCE***

A high covariance basically indicates there is a **strong relationship between the variables.**

**No two columns in this dataset are strongly related**

# **Customer Segmentation**

This section focuses on the implementation KMeans algorithm. Found the optimal number of clusters using the elbow method and Silhouette Score. 

Then drawing inferences based on the clusters obtained.
"""

from sklearn.cluster import KMeans

X_train = X.drop(['CustomerID'], axis = 1)

"""#### **Find Optimal value for k(no. of clusters)**

**Elbow Method**
"""

def try_k(X, k):
  kmeans = KMeans(n_clusters=k).fit(X)
  return kmeans.inertia_

"""Calculating inertia(Mean squared distance between each datapoint and its closest centroid) for different values of k(no. of clusters)."""

Ks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
inertias = []

for k in Ks:
  inertias.append(try_k(X_train, k))

print(inertias)

# naming the x axis
plt.xlabel('k')
# naming the y axis
plt.ylabel('inertia')

plt.xticks(Ks)
plt.plot(Ks, inertias)

plt.show()

"""*INFERENCE*
 * According to the elbow method, k = 5 is optimal number of clusters

**Silhouette Score**

Silhouette score is used to evaluate the quality of clusters created using clustering algorithms such as K-Means in terms of how well samples are clustered with other samples that are similar to each other.
"""

from sklearn.metrics import silhouette_score #To compute the silhouette score

def try_k_Silhouette(X, k):
  kmeans = KMeans(n_clusters=k).fit(X)
  return silhouette_score(X, kmeans.labels_)

Ks = [2, 3, 4, 5, 6, 7, 8, 9, 10]
scores = []

for k in Ks:
  scores.append(try_k_Silhouette(X_train, k))

print(scores)

# naming the x axis
plt.xlabel('k')
# naming the y axis
plt.ylabel('Silhouette Scores')

plt.xticks(Ks)
plt.plot(Ks, scores)

plt.show()

"""*INFERENCE*

**High Silhouette Score = Well clustered**

According to silhouette score, k = 6 is the optimal solution

#### **Final Model**

KMeans uses KMeans++ random initialization by default, so we don't need to worry about it.
"""

#We will use k = 5
model = KMeans(n_clusters = 5)
model.fit(X_train)

Clusters = model.predict(X_train)

Clusters = pd.DataFrame(data = Clusters, columns = ['Cluster'])
Clusters['CustomerID'] = X.CustomerID
Clusters.head()

"""#### **Final Data**"""

final_data = X.merge(Clusters, on = 'CustomerID', how = 'left')
final_data.head()

"""**Get Centers**"""

model.cluster_centers_

centers = pd.DataFrame(data = model.cluster_centers_, columns = X_train.columns)
centers = centers.rename_axis('center').reset_index()
centers.head()

"""**centers** and **final_data** are our final datasets which will help us find target customers and draw inferences.

# **Analyze and Visualize Results**

**Scatter Plot**
"""

#Getting unique labels
u_labels = final_data['Cluster'].unique()
 
#plotting the results with any two cols on x and y-axis:
for i in u_labels:
  x = final_data[final_data.Cluster == i]['Annual Income (k$)']
  y = final_data[final_data.Cluster == i]['Spending Score (1-100)']
  plt.xlabel('Annual Income (k$)')
  plt.ylabel('Spending Score (1-100)')
  plt.scatter( x,  y, label = i)
  plt.scatter(centers['Annual Income (k$)'], centers['Spending Score (1-100)'], color = 'black')

plt.legend()
plt.show()

"""**Relation between features**"""

centers.head()

#Line plot with x-axis as Annual Income and y-axis as Spending Score

x = centers['Annual Income (k$)']
y = centers['Spending Score (1-100)']

plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.scatter(x, y)
plt.plot(x, y)

plt.show()

#Line plot with x-axis as Age and y-axis as Spending Score

x = centers['Age']
y = centers['Spending Score (1-100)']

plt.xlabel('Age')
plt.ylabel('Spending Score (1-100)')
plt.scatter(x, y)
plt.plot(x, y)

plt.show()

#Line plot with x-axis as Female and y-axis as Spending Score

x = centers['Female']
y = centers['Spending Score (1-100)']

plt.xlabel('Female')
plt.ylabel('Spending Score (1-100)')
plt.scatter(x, y)
plt.plot(x, y)

plt.show()

#Line plot with x-axis as Male and y-axis as Spending Score

x = centers['Male']
y = centers['Spending Score (1-100)']

plt.xlabel('Male')
plt.ylabel('Spending Score (1-100)')
plt.scatter(x, y)
plt.plot(x, y)

plt.show()

#Line plot with x-axis as center and y-axis as Spending Score

x = centers['center']
y = centers['Spending Score (1-100)']

plt.xticks(centers['center'])
plt.xlabel('center')
plt.ylabel('Spending Score (1-100)')
plt.scatter(x, y)
plt.plot(x, y)

plt.show()

#Line plot with x-axis as center and y-axis as Annual Income (k$)

x = centers['center']
y = centers['Annual Income (k$)']

plt.xticks(centers['center'])
plt.xlabel('center')
plt.ylabel('Annual Income (k$)')
plt.scatter(x, y)
plt.plot(x, y)

plt.show()

#Line plot with x-axis as Male and y-axis as Annual Income (k$)

x = centers['Male']
y = centers['Annual Income (k$)']

plt.xlabel('Male')
plt.ylabel('Annual Income (k$)')
plt.scatter(x, y)
plt.plot(x, y)

plt.show()

"""***INFERENCE***

* Mean Spending Score of respective clusters is in order: 3 < 4 < 0 < 2 < 1

* Mean Annual Income of respective clusters is in order: 2 approx equal to 4 < 0 < 1 approx equal to 3

**Customers grouped in cluster 2, earn a minimum but spend a good amount** 
So they are our *1st priority customer lets name as A. category customer*

**Customers grouped in cluster 1, earn maximum and spend maximum** 
So they are our *2nd priority customer lets name as B. category customer*

**Customers grouped in cluster 0, earns average and spends average** 
So they are our *3rd priority customer let's name as C. category customer*

**Customers grouped in cluster 3, earn maximum but spend minimum** 
So they are our *4th priority customer let's name as D. category customer*

**Customers grouped in cluster 4, earn minimum and spend minimum** 
So they are our *5th priority customer let's name as E. category customer*
"""

cluster_priority = {0: 3, 1: 2, 2: 1, 3: 4, 4: 5}
priority_vs_category = {1: 'A', 2: 'B', 3: 'C', 4: 'D', 5: 'E'}